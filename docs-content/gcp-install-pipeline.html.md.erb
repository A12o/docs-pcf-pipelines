---
title: Using the GCP Install Pipeline
owner: 
---

## <a id='overview'></a> Overview
Install Pipelines deploy Pivotal Cloud Foundry for the operator’s chosen IaaS.
This documentation describes how to use PCF Pipelines to deploy PCF for GCP. 

<!---[Concourse Pipeline](embed.png)-->
This pipeline uses Terraform to create all of the infrastructure required to run PCF deployment with 3 Availability Zones on GCP according to the Reference Architecture for Pivotal Cloud Foundry on GCP.

The GCP Install Pipeline downloads artifacts from DockerHub (czero/cflinuxfs2 and custom
docker-image resources) and the configured Google Cloud Storage bucket
(terraform.tfstate file).

<!---add in note about terraform file-->

## <a id='config'></a> Pipeline Configuration

The GCP Install Pipeline consists of a:

+ parameters file. (`params.yml`). This file configures the pipeline’s environment variables. 
This file should be stored in a credential management system, such as LastPass or Credhub because it contains credentials.

+ pipelines operataions file (`pipeline.yml`). This file configures the jobs associated with this Install Pipeline. 
Jobs declare the work associated with a pipeline.
For more information on Jobs, see  the [Jobs](https://concourse.ci/concepts.html#jobs) topic in the Concourse documentation.

This table describes the jobs associated with the GCP Install Pipeline's `pipeline.yml` file:

<table>
  <tr>
    <th>Job</th>
    <th>Purpose</th>
  </tr>
  <tr> 
    <td><code>upload-opsman-image</code></td>
    <td>This job automatically uploads the latest matching version of Ops Manager.</td>
    <tr>
    <td><code>configure-director</code>
    <td>This job configures Ops Manager Director.</td>
    </tr>
    <tr>
   <td><code>deploy-director</code></td>
   <td>This job deploys the Ops Manager Director.</td>
   </tr>
   <tr>
    <td><code>upload-ert</code></td>
    <td>This job uploads Elastic Runtime.</td>
    </tr>
    <td><code>deploy-ert</code></td>
    <td>This job deploys Elastic Runtime.</td>
    <tr>
    <td><code>wipe-env</code></td>
    <td>This job tears down your Pivotal Cloud Foundry deployment. </td>
    </tr>
    <tr>
  <td><code>bootstrap-terraform-state</code></td>
  <td>This job downloads artifacts from DockerHub (czero/cflinuxfs2 and custom.</td>
</tr>
  <tr>
  <td><code>create-infrastructure</code></td>
  <td>This job creates all of the infrastructure required to run the PCF deployment.</td>
    </tr>
  </tr>
</table>

## <a id='usage'></a> Installing PCF on GCP
1. Enable the following APIs within Google Cloud Platform:
  * [GCP Compute API](https://console.cloud.google.com/apis/api/compute_component)
  * [GCP Storage API](https://console.cloud.google.com/apis/api/storage_component)
  * [GCP SQL API](https://console.cloud.google.com/apis/api/sql_component)
  * [GCP DNS API](https://console.cloud.google.com/apis/api/dns)
  * [GCP Cloud Resource Manager API](https://console.cloud.google.com/apis/api/cloudresourcemanager.googleapis.com/overview)
  * [GCP Storage Interopability](https://console.cloud.google.com/storage/settings)
1. Create a bucket in Google Cloud Storage to store the Terraform state file. 
1. Enable version control for this bucket by using the `gsutil` command line interface:
  1. `gcloud auth activate-service-account --key-file credentials.json && gsutil versioning set on gs://BUCKET-URL`
1. Edit the values marked `CHANGEME` in the `params.yml` file. 
  1. For the <code>gcp\_service_account\_key</code>, create a new service account key that has the following IAM roles:
  * Cloud SQL Admin
  * Compute Instance Admin (v1)
  * Compute Network Admin
  * Compute Security Admin
  * DNS Administrator
  * Storage Admin
1. Set the pipeline by running the following command:
  `fly --target TARGET-NAME set-pipeline --p PIPELINE-NAME --config pipeline.yml -l params.yml`
  </br>Where:
  1. `TARGET-NAME`is the target name of your Concourse instance.
  1. `PIPELINE-NAME` is the name of the pipeline in your Concourse instance. 

1.  Navigate to the pipeline URL and unpause the pipeline through the Concourse user interface. 
You can also unpause the pipeline by running the following command:
  `fly --target TARGET-NAME unpause-pipeline --pipeline PIPELINE-NAME`
  </br>Where:
  1. `TARGET-NAME`is the target name of your Concourse instance.
  1. `PIPELINE-NAME` is the name of the pipeline in your Concourse instance. 
1. Trigger the `bootstrap-terraform-state` job manually by running the following command:
  `fly --target TARRGET-NAME trigger-job --job PIPELINE-NAME/bootstrap-terraform-state`
   </br>Where:
  1. `TARGET-NAME`is the target name of your Concourse instance.
  1. `PIPELINE-NAME` is the name of the pipeline in your Concourse instance. 
1. Trigger the `create-infrastructure` job by running the following command:
  1. `fly --target TARRGET-NAME trigger-job --job PIPELINE-NAME/create-infrastructure`
   </br>Where:
  1. `TARGET-NAME`is the target name of your Concourse instance.
  1. `PIPELINE-NAME` is the name of the pipeline in your Concourse instance. 
</br>This job outputs the DNS Settings necessary required by GCP.

1. In the GCP Console Dashboard, navigate to **Network Services** > **Cloud DNS** > **Create Zone** and edit  your DNS Settings based on the output from the previous step.

1. Trigger the `create-infrastructure` job by running the following command:
`fly --target TARRGET-NAME trigger-job --job PIPELINE-NAME/configure-director`
   </br>Where:
  1. `TARGET-NAME`is the target name of your Concourse instance.
  1. `PIPELINE-NAME` is the name of the pipeline in your Concourse instance. 

## <a id='known'></a> Known Issues
###<a id='create'></a> Create Infrastructure job trying to delete SSL cert in use
Running the `create-infrastructure` job might genererate the following error:

```
google_compute_ssl_certificate.ssl-cert (destroy): 
1 error(s) occurred: google_compute_ssl_certificate.ssl-cert: Error deleting ssl certificate: googleapi: 
Error 400: The ssl_certificate resource 'projects/<redacted>/global/sslCertificates/<redacted>-gcp-lb-cert' is already being used by 'projects/<redacted>/global/targetHttpsProxies/<redacted>-gcp-https-proxy', resourceInUseByAnotherResource
```

If this occurs, update your `params.yml` file to supply the certs that were generated in the `params.yml` file when you triggered the `create-infrastructure` job.

###<a id ='wipe'></a> Wipe Environment Job
+ The `wipe-env` job does not destroy installed services. 
VMs that were created as a result of installing GCP with the Install Pipeline cannot destroyed by running the `wipe-env` job. As a workaround, delete services before running the `wipe-env` job. Otherwise, the `wipe-env` job cannot complete.

+ The `wipe-env` job does not destroy the BOSH Director VM. 
As a workaround, delete the BOSH Director VM before running the `wipe-env` job. Otherwise, the `wipe-env` job cannot complete.

###<a id ='allow-ssh'></a> Allow SSH to Ops Manager without a Jumpbox

There is no jumpbox installed as part of the Terraform scripts.
If you need to SSH into the Ops Manager VM add the 1allow-ssh` tag to the network access tags for that VM.
Add an SSH key to the instance or  use the gcloud cli that adds the SSH key automatically. 

###<a id='authorized-networks'></a> Cloud SQL Authorized Networks

Google Cloud Proxy is not yet available on BOSH-deployed VMs and Cloud SQL requires access to public networks. To resolve this, the Google Install Pipleine adds `0.0.0.0/0` to the authorized set of authorized networks  for the Cloud SQL Instance. 

## <a id='troubleshooting'></a> Troubleshooting

**Error Message:**

```
google_sql_user.diego: Creating...
  host:     "" => "%"
  instance: "" => "ph-concourse-terraform-piglet"
  name:     "" => "admin"
  password: "<sensitive>" => "<sensitive>"
Error applying plan:

1 error(s) occurred:

* google_sql_user.diego: 1 error(s) occurred:

* google_sql_user.diego: Error, failure waiting for insertion of admin into ph-concourse-terraform-piglet: Error waiting      for Insert User (op 44940cc3-df8a-4d86-9bb8-853540fa4f35): googleapi: Error 404: The Cloud SQL instance operation does not    exist., operationDoesNotExist
```
**Solution:** You cannot use "admin" as a username for MySQL.

**Error Message:**

```
“{”errors”:{“.properties.networking_point_of_entry.external_ssl.ssl_ciphers”:[“Value can’t be blank”]}}”
```
**Solution:** PCF Pipelines are not compatible with ERT 1.11.14. Redeploy with a [compatible version](index.html#compatability).

**Error Message:**

```
Error
pcf-pipelines/tasks/stage-product/task.sh: line 19: ./pivnet-product/metadata.json: No such file or directory
```
**Solution:** You are using a resource that was downloaded from an separate repository and not from PivNet. 

